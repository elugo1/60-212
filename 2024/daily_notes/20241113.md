# 11/13/2024

*Today is Wednesday, November 13: Welcome!*

Today is a work session!

--- 

### ComfyUI Worksession Hotlinks

**Image Analysis for [Custom Pixel Project](https://github.com/golanlevin/60-212/blob/main/2024/assignments/assignment_9.md#94-comfyui-1-custom-pixelai)** (Depth & Segmentation):

* Monday's [Image Analysis lecture](../../lectures/comfy/image_analysis/readme.md)
* Load [this RunComfy workflow](https://github.com/golanlevin/60-212/blob/main/lectures/comfy/image_analysis/workflows/3_image_depth_and_segmentation.json)
* Test it with [this elephant image](https://github.com/golanlevin/60-212/blob/main/lectures/comfy/image_analysis/input/original_rgb.png)
* Swap in your own image; change the Florence text prompt; download the output images.
* At [OpenProcessing](https://openprocessing.org/class/93074/#/c/94907), make a p5 sketch like [this one](https://openprocessing.org/sketch/2440728) that uses depth and/or segmentation.


**Image Synthesis [Project](https://github.com/golanlevin/60-212/blob/main/2024/assignments/assignment_9.md#95-comfyui-2-p5-in-comfy)** (p5 Guiding Stable Diffusion):

* Monday's [Image Synthesis lecture](../../lectures/comfy/image_synthesis/readme.md)
* Load [this RunComfy workflow](https://github.com/golanlevin/60-212/blob/main/lectures/comfy/image_synthesis/workflows/p5-in-comfy.json)
* Write a simple p5 sketch to control it in RunComfy, plus a text prompt. 
* Stash a backup of your p5 sketch [on OpenProcessing](https://openprocessing.org/class/93074/#/c/94911).